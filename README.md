### ç’°å¢ƒå®‰è£

- ä¸‹è¼‰ python-3.12.11-amd64.exe (python 3.12.11 å’Œ pip )
[python-3.12.11-amd64.exe](https://coatl.dev/news/2025/06/05/python-3-12-11/)

- ä¸‹è¼‰ Appserv-win32-8.6.0.exe  (Apache + PHP + MYSQL)
[Appserv-win32-8.6.0.exe](https://sourceforge.net/projects/appserv/files/AppServ%20Open%20Project/8.6.0/appserv-win32-8.6.0.exe/download)

- ä¸‹è¼‰ YOLOv7
```cmd
git clone https://github.com/WongKinYiu/yolov7.git
cd yolov7
mkdir weights
```

- é–‹å•Ÿcmdå‘½ä»¤æç¤ºå­—å…ƒ
```cmd
python --version
pip --version
```

- å®‰è£ YOLOv7 å¿…è¦å¥—ä»¶ (ä»¥Windows 10,11 ç’°å¢ƒæ¸¬è©¦éå¯è¡Œï¼Œç’°å¢ƒä¸Šå®‰è£ç¨‹åº¦å¯ä»¥ 80%ï¼Œå…¶ä»–å†çœ‹éŒ¯èª¤è¨Šæ¯ä¾åº pip install ä¾†è§£æ±º)
```text
matplotlib>=3.2.2
numpy>=1.26          
opencv-python>=4.1.1
Pillow>=7.1.2
PyYAML>=5.3.1
requests>=2.23.0
scipy>=1.4.1
torch>=1.7.0         
torchvision>=0.8.1
tqdm>=4.41.0
protobuf>=4.25      
tensorboard>=2.4.1
pandas>=1.1.4
seaborn>=0.11.0
ipython
psutil
thop                 # æ–°å¢ï¼šYOLOv7 å¸¸ç”¨
```

- å®‰è£ PyTorchï¼ˆWindowsï¼‰CUDA 12.6 ï¼Œæ¸¬è©¦éRTX2070å’ŒRTX3070é¡¯ç¤ºå¡å¯ä»¥æœ‰æ•ˆè¾¨è­˜ï¼ŒVRAMå¤§æ•ˆæœæœƒæ¯”è¼ƒå¥½
```
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
```

### å¯µç‰©ç›£æ§ç³»çµ±èªªæ˜
- æ¶æ§‹
```text
pet_monitor_system/
â”œâ”€â”€ ğŸ“¦ requirements.txt # Python ä¾è³´ 
â”œâ”€â”€ âš™ï¸ manage.py # Django ç®¡ç† 
â”œâ”€â”€ ğŸ¯ pet_monitor/ # Django ä¸»å°ˆæ¡ˆ 
â”œâ”€â”€ ğŸ“Š monitor/ # ç›£æ§æ‡‰ç”¨ (API + æ¨¡å‹) 
â”œâ”€â”€ ğŸ¤– model/ # AI æª¢æ¸¬å™¨ 
â”œâ”€â”€ ğŸ“º stream/ # ä¸²æµè™•ç† 
â”œâ”€â”€ ğŸ“„ templates/ # HTML æ¨¡æ¿
â”œâ”€â”€    yolov7 å½±åƒè¾¨è­˜
â”œâ”€â”€    weights æ”¾æœ‰yolov7 è¨“ç·´å‡ºä¾†çš„best.pt æ¨¡å‹æ¬Šé‡
â”œâ”€â”€    venv è™›æ“¬ç’°å¢ƒ(pip å®‰è£å¥—ä»¶)
```


```text
pet_monitor_system/
â”œâ”€â”€ manage.py                  # Django ä¸»å…¥å£
â”œâ”€â”€ pet_monitor/               # Django è¨­å®š
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py            # é€£ç·š MySQL / éœæ…‹æª”æ¡ˆ / Django REST Framework
â”‚   â”œâ”€â”€ urls.py                # å‰ç«¯é é¢èˆ‡ API è·¯ç”±
â”‚   â””â”€â”€ wsgi.py
â”œâ”€â”€ monitor/                   # è¡Œç‚ºç›£æ§ (API + æ¨¡å‹çµæœå¯«å…¥ DB)
â”‚   â”œâ”€â”€ models.py              # Pet, Behavior
â”‚   â”œâ”€â”€ views.py               # REST API å¯¦ä½œ
â”‚   â”œâ”€â”€ serializers.py
â”‚   â”œâ”€â”€ urls.py
â”‚   â””â”€â”€ ai_inference.py        # YOLOv7 + OpenCV æ¨è«–
â”œâ”€â”€ stream/                    # ä¸²æµæœå‹™
â”‚   â”œâ”€â”€ views.py (MJPEG)
â”‚   â””â”€â”€ urls.py
â”œâ”€â”€ templates/                 # HTML é é¢
â”‚   â”œâ”€â”€ index.html             # é¦–é 
â”‚   â”œâ”€â”€ help.html              # å¹«åŠ©é 
â”‚   â””â”€â”€ status.html            # ç‹€æ…‹é 
â”œâ”€â”€ yolov7/                    
â”‚   â”œâ”€â”€ hubconf.py                 # hubconf.py æœƒæª¢æŸ¥ requirement å¿…è¦çš„å®‰è£å¥—ä»¶ç‰ˆæœ¬é™åˆ¶
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ common.py
â”‚   â”‚   â”œâ”€â”€ experimental.py
â”‚   â”‚   â””â”€â”€ ...
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ augmentations.py   âœ… é€™è£¡
â”‚   â”œâ”€â”€ general.py
â”‚   â”œâ”€â”€ torch_utils.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ train.py
â”œâ”€â”€ detect.py
â””â”€â”€ ...
â”œâ”€â”€ model/                     # AI æª¢æ¸¬å™¨ 
â”œâ”€â”€ db_init.sql                # MySQL åˆå§‹åŒ–è³‡æ–™
â””â”€â”€ start.bat                  # ä¸€éµå•Ÿå‹• (Windows)
```

- å‰µå»ºå°ˆæ¡ˆè³‡æ–™å¤¾
```cmd
cd C:\Users\ä½ çš„ä½¿ç”¨è€…åç¨±\Downloads\pet_monitor_mysql57_with_video
```

- å»ºç«‹è™›æ“¬ç’°å¢ƒï¼Œå¾Œé¢æŒ‡ä»¤æ“ä½œéƒ½åœ¨é€™å€‹è™›æ“¬ç’°å¢ƒåš
```cmd
python -m venv venv
venv\Scripts\activate
```

- requirements-windows.txt å…§å®¹å¦‚ä¸‹:
```text
# ==== Core numeric/science ====
numpy==2.0.2
scipy==1.16.2
pandas==2.2.2
pytz==2025.2
python-dateutil==2.9.0.post0
matplotlib==3.10.0
seaborn==0.13.2

# ==== CV / IO ====
opencv-python==4.12.0.88
Pillow==11.3.0

# ==== YOLOv7 helpers ====
PyYAML==6.0.2
tqdm==4.67.1
tensorboard==2.19.0
protobuf==5.29.5
psutil==5.9.5
thop

# ==== Networking (requests stack) ====
requests==2.32.4
urllib3==2.5.0
chardet==5.2.0
idna==3.10
certifi==2025.8.3

# ==== Torch / TorchVision are installed separately (see above) ====
# (Do NOT pin here to avoid missing CUDA wheels on Windows)

# ==== Extras to satisfy recent torch/torchvision import paths ====
typing_extensions==4.15.0
sympy==1.13.3
packaging==25.0
```

- åœ¨venv è™›æ“¬ç’°å¢ƒå€¼åŸ·è¡Œ requirements-windows.txt
```cmd
pip install -r requirements-windows.txt
```

### âš™ï¸ å¾Œç«¯æ ¸å¿ƒè¨­å®š
- settings.py é€£ç·š MySQL
```python
import pymysql
pymysql.install_as_MySQLdb()

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.mysql',
        'NAME': 'pet_monitor',
        'USER': 'root',
        'PASSWORD': '',   # å¦‚æœæœ‰å¯†ç¢¼è¦æ”¹
        'HOST': '127.0.0.1',
        'PORT': '3306',
        'OPTIONS': {'charset': 'utf8mb4'},
    }
}


INSTALLED_APPS = [
    'rest_framework',
    'monitor',
    'stream',
]
```

- monitor/models.py
```python
from django.db import models

class Pet(models.Model):
    name = models.CharField(max_length=50)

class Behavior(models.Model):
    pet = models.ForeignKey(Pet, on_delete=models.CASCADE)
    behavior = models.CharField(max_length=20)  # eating, toilet, lying
    confidence = models.FloatField()
    timestamp = models.DateTimeField(auto_now_add=True)
    duration = models.IntegerField(default=0)  # ç§’
```

### ğŸ“„ API è·¯ç”± (Django REST Framework)
```text
/api/pets/ â†’ å–å¾—å¯µç‰©è³‡æ–™
/api/behaviors/ â†’ è¡Œç‚ºè¨˜éŒ„
/api/realtime/ â†’ å³æ™‚è¾¨è­˜çµæœ
/api/stream/video/ â†’ å½±åƒä¸²æµ (MJPEG)
/api/stream/stop/ â†’ åœæ­¢ä¸²æµ
```

### ğŸ¬ MySQL åˆå§‹åŒ– (db_init.sql)
```text
CREATE DATABASE IF NOT EXISTS pet_monitor CHARACTER SET utf8mb4;
USE pet_monitor;

CREATE TABLE pet_monitor_pet (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(50)
);

CREATE TABLE pet_monitor_behavior (
    id INT AUTO_INCREMENT PRIMARY KEY,
    pet_id INT,
    behavior VARCHAR(20),
    confidence FLOAT,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    duration INT DEFAULT 0,
    FOREIGN KEY (pet_id) REFERENCES pet_monitor_pet(id)
);

INSERT INTO pet_monitor_pet (name) VALUES ('å°é»‘'), ('å°ç™½');
```

### å»ºç«‹è³‡æ–™è¡¨ & å•Ÿå‹• Django
```text
python manage.py migrate
python manage.py runserver 127.0.0.1:8000
```

- é–‹å•Ÿç€è¦½å™¨ â†’ http://127.0.0.1:8000/
- é¦–é ï¼šå³æ™‚ä¸²æµã€å¥åº·é æ¸¬
- å¹«åŠ©ï¼šå¿«é€Ÿé–‹å§‹ + API æ–‡ä»¶
- ç‹€æ…‹ï¼šç³»çµ±ç‹€æ…‹æª¢æŸ¥

- é–‹å•Ÿé¦–é ï¼Œåœ¨ç€è¦½å™¨æ‰“é–‹ï¼š
```text
http://127.0.0.1:8000/
```

- æ¸¬è©¦ Help é ï¼Œåœ¨ç€è¦½å™¨æ‰“é–‹ï¼š
```text
http://127.0.0.1:8000/help/
```

- æ¸¬è©¦ Status é ï¼Œåœ¨ç€è¦½å™¨æ‰“é–‹ï¼š
```text
http://127.0.0.1:8000/status/
```

- æ¸¬è©¦ API (å¾Œç«¯)
å³æ™‚è¾¨è­˜ (å‡è³‡æ–™å›æ‡‰)
```cmd
curl http://127.0.0.1:8000/api/realtime/
```
âœ… æ‡‰è©²æœƒå›ï¼š
```json
{
  "current_behavior": "ç„¡æª¢æ¸¬",
  "confidence": 0.0,
  "health_status": "normal"
}
```

- æ¸¬è©¦ä¸²æµ APIï¼ˆé–‹å•Ÿä¸²æµï¼‰
```cmd
curl http://127.0.0.1:8000/api/stream/video/
```
âœ… é æœŸå›æ‡‰ï¼š
```json
{"ok": true}
```

- æ¸¬è©¦ä¸²æµ APIï¼ˆé—œé–‰ä¸²æµï¼‰
```cmd
curl http://127.0.0.1:8000/api/stream/stop/
```
âœ… é æœŸå›æ‡‰ï¼š
```json
{"stopped": true}
```

- æ¸¬è©¦è¡Œç‚ºç´€éŒ„æ¸…å–®
```cmd
curl http://127.0.0.1:8000/api/behaviors/
```
âœ… é æœŸå›æ‡‰ï¼š
```json
{"results":[]}
```

- å–å¾—å¯µç‰©æ¸…å–® http://127.0.0.1:8000/api/pets/
```json
{"results":[{"id":1,"name":"å°é»‘"}]}
```

æ¸¬è©¦è³‡æ–™åº«åŒ¯å…¥ db_init.sql å¾Œåˆ° MySQL æ‰“é–‹ phpMyAdmin æˆ– MySQL CLIï¼ŒåŸ·è¡Œï¼š
```sql
SELECT * FROM pet_monitor_pet;
```

### è®“ Django 3.2 LTS æ”¯æ´ MySQL 5.7
```text
Django==3.2.25
djangorestframework==3.14.0
PyMySQL==1.1.1
```


# ç¢ºèª YOLOv7 + OpenCV ä¸²æµç¨‹å¼

- å‰ç«¯æŒ‰ä¸‹ã€Œé–‹å§‹ç›£æ§ã€å¾Œï¼Œå¯¦éš›ä¸Šæ‡‰è©²å‘¼å« stream/ app è£¡çš„ä¸²æµé‚è¼¯ï¼ˆDjango View æˆ–å–®ç¨ Python ç¨‹å¼ï¼‰ã€‚

ğŸ‘‰ ä¸€å€‹ OpenCV ä¸²æµç¨‹å¼ï¼Œä¾‹å¦‚ï¼š
```python
# stream/views.py
from django.http import StreamingHttpResponse
import cv2

def gen_frames():
    cap = cv2.VideoCapture(0)  # æ”å½±æ©Ÿ
    while True:
        success, frame = cap.read()
        if not success:
            break
        else:
            # è½‰æˆ JPEG
            ret, buffer = cv2.imencode('.jpg', frame)
            frame = buffer.tobytes()
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')

def video_feed(request):
    return StreamingHttpResponse(gen_frames(), content_type='multipart/x-mixed-replace; boundary=frame')
```
ç„¶å¾Œåœ¨ pet_monitor/urls.py åŠ ä¸€æ¢ï¼š
```
path("video_feed/", video_feed, name="video_feed")
```

- å‰ç«¯ HTML (templates/index.html) æŠŠ <img> æŒ‡å‘å¾Œç«¯ä¸²æµ URLï¼š
```html
<div>
  <h3>å³æ™‚ç›£æ§</h3>
  <img id="stream" src="/video_feed/" width="640" height="480" />
</div>
```

- å¦‚æœè¦åŠ  YOLOv7 åµæ¸¬
åœ¨ gen_frames() è£¡ï¼ŒæŠŠ frame ä¸Ÿåˆ° YOLOv7 æ¨¡å‹è·‘ï¼Œç•«æ¡†å¾Œå†é€å›ç€è¦½å™¨ã€‚åƒé€™æ¨£ï¼š
```python
# å‡è¨­å·²è¼‰å…¥ yolo æ¨¡å‹
results = model(frame)  # YOLO åµæ¸¬
for *xyxy, conf, cls in results.xyxy[0]:
    label = f"{model.names[int(cls)]} {conf:.2f}"
    cv2.putText(frame, label, (int(xyxy[0]), int(xyxy[1]) - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    cv2.rectangle(frame, (int(xyxy[0]), int(xyxy[1])),
                  (int(xyxy[2]), int(xyxy[3])), (0, 255, 0), 2)
```html


### ä¿®æ”¹
1. stream/views.py
åœ¨ gen_frames() ä¸­ï¼š
è¼‰å…¥ YOLOv7 æ¨¡å‹ï¼ˆtorchï¼‰ã€‚
æ¯ä¸€å¹€é€é€²æ¨¡å‹æ¨è«–ã€‚
å°‡åµæ¸¬åˆ°çš„æ¡†æ¡†èˆ‡åˆ†é¡ï¼ˆåƒé£¯ã€ä¸Šå»æ‰€ã€è¶´ä¸‹ï¼‰ç•«åˆ° frame ä¸Šã€‚
å†è¼¸å‡ºç‚º MJPEGã€‚
ç¯„ä¾‹ç¨‹å¼ç‰‡æ®µï¼š
```python
import torch

# è¼‰å…¥æ¨¡å‹ï¼ˆè«‹ç¢ºèª weights/best.pt å­˜åœ¨ï¼‰
MODEL_PATH = "weights/best.pt"
model = torch.hub.load("WongKinYiu/yolov7", "custom", MODEL_PATH, trust_repo=True)

def gen_frames():
    cap = _open_camera()
    while True:
        ok, frame = cap.read()
        if not ok:
            break
        # æ¨è«–
        results = model(frame)
        # è½‰æ›æˆå¸¶æ¡†çš„ numpy å½±åƒ
        frame = results.render()[0]
        # è¼¸å‡º JPEG
        ok, buffer = cv2.imencode(".jpg", frame)
        if ok:
            yield (b'--frame\\r\\nContent-Type: image/jpeg\\r\\n\\r\\n' +
                   buffer.tobytes() + b'\\r\\n')
```

### æ•´åˆæ•ˆæœ
- ä½ ç€è¦½ /video_feed/ â†’ å³æ™‚çœ‹åˆ°é¡é ­ç•«é¢ + YOLO åµæ¸¬æ¡†ã€‚
- åµæ¸¬åˆ°çš„åˆ†é¡æœƒé¡¯ç¤ºåœ¨æ¡†æ¡†ä¸Šï¼ˆå¦‚ eating, toilet, lyingï¼‰ã€‚
- best.pt éœ€æ”¾åœ¨ weights/ è³‡æ–™å¤¾åº•ä¸‹ã€‚

# é€²éšæ‡‰ç”¨
### é€™ä»½ç¨‹å¼æœƒæœ‰ï¼š
- è¼‰å…¥ YOLOv7 æ¨¡å‹ï¼ˆweights/best.ptï¼‰ã€‚
- ä½¿ç”¨ OpenCV æ“·å–æ”å½±æ©Ÿå½±åƒã€‚
- æ¯ä¸€å¹€è·‘æ¨è«–ä¸¦ç¹ªè£½æ¡†æ¡†èˆ‡æ¨™ç±¤ã€‚
- é€é Django StreamingHttpResponse è¼¸å‡ºç‚º MJPEGã€‚
```python
from django.http import StreamingHttpResponse
from django.views.decorators import gzip
import cv2
import numpy as np
import torch
import os

# æ”å½±æ©Ÿä¾†æºï¼š0 = å…§å»ºæ”å½±æ©Ÿï¼›ä¹Ÿå¯ä»¥æ”¹æˆ rtsp://... æˆ– http://...
CAMERA_SOURCE = 0

# æ¨¡å‹è·¯å¾‘
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
MODEL_PATH = os.path.join(BASE_DIR, "weights", "best.pt")

# è¼‰å…¥ YOLOv7 æ¨¡å‹
print(f"è¼‰å…¥ YOLOv7 æ¨¡å‹: {MODEL_PATH}")
model = torch.hub.load("yolov7", "custom", path=MODEL_PATH, source="local")

def _open_camera():
    cap = cv2.VideoCapture(CAMERA_SOURCE)
    if not cap.isOpened():
        cap.open(CAMERA_SOURCE)
    return cap

def gen_frames():
    cap = _open_camera()
    if not cap or not cap.isOpened():
        blank = (255 * np.ones((240, 320, 3), dtype=np.uint8))
        ok, buffer = cv2.imencode('.jpg', blank)
        yield (b'--frame\r\nContent-Type: image/jpeg\r\n\r\n' +
               buffer.tobytes() + b'\r\n')
        return

    try:
        while True:
            ok, frame = cap.read()
            if not ok:
                break

            # YOLO æ¨è«–
            results = model(frame)
            frame = results.render()[0]  # å–å¸¶æ¨™è¨»çš„å½±åƒ

            ok, buffer = cv2.imencode(".jpg", frame)
            if not ok:
                continue
            jpg = buffer.tobytes()
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + jpg + b'\r\n')
    finally:
        cap.release()

@gzip.gzip_page
def video_feed(request):
    return StreamingHttpResponse(gen_frames(),
                                 content_type='multipart/x-mixed-replace; boundary=frame')
```

# é‡é»ä¿®å¾©
æ”¾ç½® YOLOv7 åŸå§‹ç¢¼èˆ‡æ¬Šé‡
pet_monitor_system/
â”œâ”€â”€ yolov7/                 â† é€™è£¡æ”¾ github å°ˆæ¡ˆï¼ˆgit clone ä¸‹ä¾†ï¼‰
â”‚   â”œâ”€â”€ hubconf.py
â”‚   â””â”€â”€ requirements.txt    ï¼ˆå…§å« numpy<1.24 çš„ç›¸ä¾å®£å‘Šï¼‰
â””â”€â”€ weights/
    â””â”€â”€ best.pt             â† ä½ çš„è¨“ç·´æ¬Šé‡

### weights
- æŠŠ NMS æ”¹åœ¨ CPU ä¸Šåš
- æ”¹ yolov7\utils\general.py çš„ non_max_suppression()ï¼Œåœ¨å‘¼å« NMS å‰æŠŠè³‡æ–™æ¬åˆ° CPUï¼šæ‰¾åˆ°é€™è¡Œï¼ˆå¤§ç´„åœ¨å‡½å¼ä¸­éƒ¨ï¼‰ï¼š
```python
i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS
```
æ”¹æˆï¼š
```python
# åœ¨ CPU ä¸Šåš NMSï¼ˆé¿å… CUDA ç‰ˆ torchvision::nms ç¼ºå¤±ï¼‰
i = torchvision.ops.nms(boxes.float().cpu(), scores.cpu(), iou_thres)
```

### ä¿®æ”¹ YOLOv7 çš„ models/experimental.py
- æ‰“é–‹ yolov7/models/experimental.pyï¼Œæ‰¾åˆ°ï¼š
```python
ckpt = torch.load(w, map_location=map_location)  # load
```
æ”¹æˆ:
```python
ckpt = torch.load(w, map_location=map_location, weights_only=False)  # load (PyTorch>=2.6)
```
è¨­ weights_only=False æœƒå›åˆ°èˆŠè¡Œç‚ºï¼›åªåœ¨ä½ ä¿¡ä»»æ¬Šé‡ä¾†æºæ™‚ä½¿ç”¨

- **é©—è­‰å®‰è£æ˜¯å¦çœŸçš„æœ‰ NMS CUDA æ ¸å¿ƒï¼š**
```python
python - <<PY
import torch, torchvision
print('torch', torch.__version__, 'cuda', torch.version.cuda, 'is_available', torch.cuda.is_available())
print('torchvision', torchvision.__version__)
import torch.ops
print('has torchvision nms:', hasattr(torch.ops.torchvision, 'nms'))
PY
```
### ğŸ”é€²éšæ‡‰ç”¨æ’é™¤æ–¹æ³•
- è¾¨è­˜å¤±æ•—çš„å¯èƒ½åŸå› 
> 2.ç›¸æ©Ÿè§£æåº¦ / å¹€ç‡å¤ªä½
- OpenCV é è¨­å¯èƒ½åªæŠ“åˆ° 640Ã—480ï¼Œå°è‡´å°ç‰©ä»¶è¾¨è­˜ä¸åˆ°ã€‚
- éœ€è¦åœ¨ VideoCapture è£¡è¨­å®šè§£æåº¦ï¼Œä¾‹å¦‚ï¼š
```python
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
cap.set(cv2.CAP_PROP_FPS, 30)
```

> 2.YOLOv7 æ¨è«–åœ–ç‰‡å¤§å° (img-size) å¤ªå°1.
- å¦‚æœ letterbox é è¨­ç”¨ 640ï¼Œå°æ–¼å°ç‰©ä»¶ä¸å¤ æ¸…æ¥šã€‚
- å¯ä»¥æ”¹æˆ 960 æˆ– 1280ï¼Œä½†æœƒå¢åŠ  GPU è² æ“”ã€‚
> 3.ä¿¡å¿ƒé–¾å€¼ (confidence threshold) è¨­å¤ªé«˜
- å¦‚æœä½ ç”¨äº† --conf 0.5ï¼Œå°ç‰©ä»¶å¯èƒ½è¢«æ¿¾æ‰ã€‚
- å»ºè­°èª¿ä½åˆ° 0.25 å·¦å³ã€‚

CUDA æ²’å®Œå…¨å•Ÿç”¨

ç›®å‰ torch å¯ä»¥æŠ“åˆ° GPUï¼Œä½†æ¨è«–å¯èƒ½ä»åœ¨ CPUã€‚

ç¢ºèª model.to(device) å’Œ img.to(device) æ˜¯å¦æ­£ç¢ºæ¬åˆ° GPUã€‚

ç›¸æ©Ÿå…‰ç·š / é¡é ­ä½ç½®å½±éŸ¿

YOLO æ¨¡å‹å°å…‰ç·šæ•æ„Ÿï¼Œå¦‚æœå¤ªæš—æˆ–è§’åº¦ä¸å¥½ï¼Œæ¡†é¸æœƒä¸ç©©ã€‚


### æ•´åˆ GPU ä½¿ç”¨ã€ç›¸æ©Ÿé«˜ç•«è³ª (1280Ã—720)ã€YOLOv7 æ¨è«–æœ€ä½³åŒ–ï¼š
```python
import cv2
import torch
import numpy as np
from django.http import StreamingHttpResponse, JsonResponse
from django.shortcuts import render
from yolov7.models.experimental import attempt_load
from yolov7.utils.general import non_max_suppression, scale_coords
from yolov7.utils.datasets import letterbox

# ---------------------------
# YOLOv7 æ¨¡å‹è¨­å®š
# ---------------------------
WEIGHTS = "weights/best.pt"  # è«‹æ”¾åˆ°å°ˆæ¡ˆå…§çš„ weights/ ç›®éŒ„
DEVICE = "cuda:0" if torch.cuda.is_available() else "cpu"
print(f"âœ… ä½¿ç”¨è£ç½®: {DEVICE}")

# è¼‰å…¥æ¨¡å‹
model = attempt_load(WEIGHTS, map_location=DEVICE)
model.to(DEVICE)
model.eval()
print("âœ… YOLOv7 æ¨¡å‹è¼‰å…¥å®Œæˆ")

# ä¿¡å¿ƒèˆ‡ NMS é–¾å€¼
CONF_THRES = 0.25
IOU_THRES = 0.45
IMG_SIZE = 640  # å¯æ”¹ 960 / 1280 æå‡æ•ˆæœ

# ---------------------------
# æ¨è«– & ç¹ªè£½çµæœ
# ---------------------------
def draw_results(frame, detections, names):
    for *xyxy, conf, cls in detections:
        label = f"{names[int(cls)]} {conf:.2f}"
        xyxy = [int(x) for x in xyxy]
        cv2.rectangle(frame, (xyxy[0], xyxy[1]), (xyxy[2], xyxy[3]), (0, 255, 0), 2)
        cv2.putText(frame, label, (xyxy[0], xyxy[1] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    return frame

def yolo_inference(frame):
    img = letterbox(frame, IMG_SIZE)[0]
    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR â†’ RGB
    img = np.ascontiguousarray(img)
    img = torch.from_numpy(img).to(DEVICE)
    img = img.float() / 255.0
    if img.ndimension() == 3:
        img = img.unsqueeze(0)

    # æ¨¡å‹æ¨è«–
    with torch.no_grad():
        pred = model(img)[0]
        pred = non_max_suppression(pred, CONF_THRES, IOU_THRES)

    detections = []
    for det in pred:
        if det is not None and len(det):
            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], frame.shape).round()
            detections = det.cpu().numpy()
    return detections

# ---------------------------
# ç›¸æ©Ÿä¸²æµç”¢ç”Ÿå™¨
# ---------------------------
def gen_frames(cam_id=1):  # é è¨­ä½¿ç”¨ camera 1
    cap = cv2.VideoCapture(cam_id)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    cap.set(cv2.CAP_PROP_FPS, 30)

    names = model.names if hasattr(model, "names") else [str(i) for i in range(1000)]

    while True:
        success, frame = cap.read()
        if not success:
            break

        detections = yolo_inference(frame)
        frame = draw_results(frame, detections, names)

        # ç·¨ç¢¼è¼¸å‡º
        ret, buffer = cv2.imencode(".jpg", frame)
        frame = buffer.tobytes()
        yield (b"--frame\r\n"
               b"Content-Type: image/jpeg\r\n\r\n" + frame + b"\r\n")

    cap.release()

# ---------------------------
# Django è¦–åœ–
# ---------------------------
def index(request):
    return render(request, "index.html")

def video_feed(request):
    cam_id = int(request.GET.get("source", 1))  # å¯ç”¨ ?source=0 / 1 åˆ‡æ›ç›¸æ©Ÿ
    return StreamingHttpResponse(gen_frames(cam_id),
                                 content_type="multipart/x-mixed-replace; boundary=frame")

def api_status(request):
    return JsonResponse({"status": "ok", "device": DEVICE})
```

### æŠŠã€Œè¾¨è­˜åˆ°å°±å›å¯«åˆ°è³‡æ–™åº«ã€æ•´é€² stream/views.pyã€‚ä¸‹é¢é€™ä»½å®Œæ•´æª”æ¡ˆæœƒï¼š

ä»¥ YOLOv7 åšæ¨è«–ï¼ˆæ”¯æ´ CUDAï¼Œè‡ªå‹• fallback åˆ° CPUï¼‰

ä¸²æµ /video_feed/?source=<index>ï¼ˆindex ç”¨ä½ çš„ camera ç·¨è™Ÿï¼‰

æ¯ç­†åµæ¸¬åˆ°çš„ç‰©ä»¶ï¼ˆå«ä¿¡å¿ƒå€¼ï¼‰â†’ ä¾é–€æª»èˆ‡ç¯€æµè¦å‰‡å¯«å…¥ pet_monitor_behavior è¡¨

æä¾›æŸ¥è©¢ API

GET /api/realtime/ï¼šå›å‚³æœ€è¿‘ä¸€æ¬¡è¾¨è­˜ç‹€æ…‹

GET /api/behaviors/ï¼šå›å‚³æœ€è¿‘ 50 ç­†è³‡æ–™

å‡è¨­ä½ å·²ç¶“åœ¨ monitor/models.py å®šç¾©äº†ï¼š
```python
class PetMonitorBehavior(models.Model):
    behavior = models.CharField(max_length=100)
    confidence = models.FloatField(default=0.0)
    health_status = models.CharField(max_length=20, default="normal")
    timestamp = models.DateTimeField(auto_now_add=True)
    class Meta:
        db_table = "pet_monitor_behavior"
```

### é—œæ–¼æ”¾å…¥YOLOv7 è³‡æ–™å¤¾å¾Œçš„  stream/views.py
```python
# stream/views.py
import os
import sys
import time
from pathlib import Path

import cv2
import numpy as np
import torch
from django.http import StreamingHttpResponse, JsonResponse, Http404
from django.shortcuts import render
from django.views.decorators.gzip import gzip_page
from django.views.decorators.http import require_GET
from monitor.models import PetMonitorBehavior

# ========== YOLOv7 utils ==========
from yolov7.utils.general import non_max_suppression, scale_coords, check_img_size
from yolov7.utils.datasets import letterbox
from yolov7.models.experimental import attempt_load
from yolov7.utils.torch_utils import select_device

# ========== å…¨åŸŸè¨­å®š ==========
PROJECT_ROOT = Path(__file__).resolve().parents[1]
DEFAULT_CAMERA_INDEX = 1   # ğŸ”¹å›ºå®š Camera 1
WEIGHTS = str(PROJECT_ROOT / "weights" / "best.pt")

# GPU / CPU é¸æ“‡
device = select_device("0" if torch.cuda.is_available() else "cpu")
print(f"[Init] ä½¿ç”¨è£ç½®: {device}")

# è¼‰å…¥ YOLOv7
print(f"[Init] è¼‰å…¥ YOLOv7 æ¬Šé‡: {WEIGHTS}")
model = attempt_load(WEIGHTS, map_location=device)
model.eval()
try:
    model.fuse()
except Exception:
    pass
print("âœ… YOLOv7 æ¨¡å‹è¼‰å…¥å®Œæˆ")

CONF_THRES = 0.25
IOU_THRES = 0.45

# YOLO labels
names = model.module.names if hasattr(model, "module") else model.names

# ========== Camera Open ==========
def _open_capture(index: int):
    print(f"[Camera] å˜—è©¦é–‹å•Ÿ index={index} via DSHOW")
    cap = cv2.VideoCapture(index, cv2.CAP_DSHOW)
    if not cap.isOpened():
        raise Http404(f"ç„¡æ³•é–‹å•Ÿæ”å½±æ©Ÿ index={index}")

    # ğŸ”¹é–å®šè§£æåº¦
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    return cap

# ========== DB å›å¯« ==========
def save_detection(behavior: str, confidence: float, health_status: str = "normal"):
    try:
        PetMonitorBehavior.objects.create(
            behavior=behavior,
            confidence=float(confidence),
            health_status=health_status,
        )
    except Exception as e:
        print(f"[WARN] save_detection failed: {e}")

# ========== ä¸²æµç”¢ç”Ÿå™¨ ==========
def gen_frames(
    source=DEFAULT_CAMERA_INDEX,
    img_size=640,
    conf_thres=0.25,
    iou_thres=0.45,
    health_status_default="normal",
):
    stride = 32
    img_size = check_img_size(img_size, s=stride)

    cap = _open_capture(int(source))

    fail_count, MAX_FAIL = 0, 30
    try:
        while True:
            ok, frame = cap.read()
            if not ok or frame is None:
                fail_count += 1
                if fail_count >= MAX_FAIL:
                    print(f"[Camera] è®€å–å¤±æ•— {MAX_FAIL} æ¬¡ï¼ŒçµæŸä¸²æµ")
                    break
                time.sleep(0.1)
                continue
            else:
                fail_count = 0

            img0 = frame.copy()
            lb = letterbox(img0, img_size, stride=stride, auto=True)[0]
            img = lb[:, :, ::-1].transpose(2, 0, 1)
            img = np.ascontiguousarray(img)
            img = torch.from_numpy(img).to(device).float() / 255.0
            if img.ndimension() == 3:
                img = img.unsqueeze(0)

            with torch.no_grad():
                pred = model(img)[0]

            pred = non_max_suppression(pred, conf_thres, iou_thres)[0]

            if pred is not None and len(pred):
                pred[:, :4] = scale_coords(img.shape[2:], pred[:, :4], img0.shape).round()
                for *xyxy, conf, cls in pred:
                    x1, y1, x2, y2 = map(int, xyxy)
                    label = names[int(cls)]
                    confidence = float(conf)

                    save_detection(label, confidence, health_status_default)

                    cv2.rectangle(img0, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    cv2.putText(img0, f"{label} {confidence:.2f}",
                                (x1, max(0, y1 - 5)),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.6,
                                (0, 255, 0), 2)

            ok, buffer = cv2.imencode(".jpg", img0)
            if not ok:
                continue
            yield (b"--frame\r\n"
                   b"Content-Type: image/jpeg\r\n\r\n" + buffer.tobytes() + b"\r\n")
    finally:
        cap.release()
        print("[Camera] å·²é‡‹æ”¾è³‡æºï¼Œä¸²æµçµæŸ")

# ========== Django Views ==========
def index(request):
    return render(request, "index.html")

@gzip_page
@require_GET
def api_video(request):
    """å›ºå®š Camera 1 çš„ MJPEG ä¸²æµ"""
    return StreamingHttpResponse(
        gen_frames(source=DEFAULT_CAMERA_INDEX),
        content_type="multipart/x-mixed-replace; boundary=frame",
    )

@require_GET
def realtime_status(request):
    return JsonResponse({"status": "ok"})

@require_GET
def pets_api(request):
    records = (
        PetMonitorBehavior.objects.all()
        .order_by("-timestamp")[:10]
        .values("id", "behavior", "confidence", "health_status", "timestamp")
    )
    return JsonResponse(list(records), safe=False)
```
âœ… ç‰¹é»ï¼š
- ç›´æ¥é–å®š Camera 1ï¼ˆindex=1, DSHOW, 1280Ã—720ï¼‰
- /api/stream/video/ æœƒå›å‚³ MJPEG ä¸²æµ
- å¤±æ•— 30 æ¬¡æœƒè‡ªå‹•é€€å‡ºï¼ˆé¿å…å¡æ­»é»‘ç•«é¢ï¼‰
- YOLOv7 åµæ¸¬çµæœæœƒå³æ™‚å¯«å…¥ DBï¼ˆPetMonitorBehaviorï¼‰

# è³‡æ–™åº«ç¼ºæ¬„ä½ ä¿®å¾©
### ç”¨ Django migrations ä¿®å¥½ï¼ˆå»ºè­°ï¼‰
åœæ‰ runserverï¼ˆæŒ‰ Ctrl+Cï¼‰ã€‚
ç¢ºèª monitor åœ¨ settings.py çš„ INSTALLED_APPS è£¡é¢ã€‚
```cmd
python manage.py makemigrations monitor
```
å¦‚æœä½ çœ‹åˆ°å®ƒèªªå·²æ¯”å°æˆåŠŸä½†æ¬„ä½ä»ä¸åœ¨ï¼Œä»£è¡¨å‰›æ‰åªåšäº†å°é½Šï¼Œé‚„éœ€è¦çœŸæ­£æ–°å¢æ¬„ä½çš„é·ç§»æª”ã€‚é‚£å°±åŸ·è¡Œ
```cmd
# è®“ Django åµæ¸¬å·®ç•°å¾Œç”¢ç”Ÿã€Œæ–°å¢æ¬„ä½ã€çš„é·ç§»
python manage.py makemigrations monitor
python manage.py migrate monitor
```
### ç›´æ¥ç”¨ SQL è£œæ¬„ä½ï¼ˆå¿«é€Ÿä¿®ã€è·³éé·ç§»ï¼‰
8 åƒ…åœ¨ä½ ç¢ºå®šè¦æ‰‹å‹•æ”¹è¡¨ã€ä¹‹å¾Œå†è®“é·ç§»å°é½Šæ™‚ä½¿ç”¨ã€‚
```sql
ALTER TABLE pet_monitor_behavior
ADD COLUMN health_status VARCHAR(20) NOT NULL DEFAULT 'normal' AFTER confidence;
```
å¦‚æœé‚„æ²’æœ‰ confidence æ¬„ä½ï¼Œå…ˆè£œå®ƒï¼š
```sql
ALTER TABLE pet_monitor_behavior
ADD COLUMN confidence DOUBLE NOT NULL DEFAULT 0 AFTER behavior;
```
è£œå®Œå¾Œï¼Œè®“ Django é·ç§»ç‹€æ…‹å°é½Šï¼ˆé¿å…ä¹‹å¾Œé·ç§»å†æƒ³æ”¹åŒä¸€æ¬„ä½ï¼‰ï¼š
```cmd
python manage.py makemigrations monitor
python manage.py migrate monitor --fake
```

# ğŸ”§ YOLOv7 çš„ hubconf.py å¡æ§è§£æ±ºæ–¹å¼

YOLOv7 çš„ hubconf.py æœƒåŸ·è¡Œé€™æ®µï¼š
```python
check_requirements(Path(__file__).parent / 'requirements.txt', exclude=('pycocotools', 'thop'))
```

é€™è¡Œæœƒå»è®€ yolov7/requirements.txtï¼Œè£¡é¢å¯«è‘—ï¼š
```text
protobuf<4.21.3
```
æ”¹æˆ
```text
protobuf>=3.19.0
```
æˆ–è€…ç›´æ¥åˆªæ‰


ä½†å¯¦éš›ä¸Š torch + protobuf 5.x åœ¨ Python 3.12 æ˜¯ ç›¸å®¹çš„ã€‚
æ‰€ä»¥æˆ‘å€‘è¦ ä¿®æ”¹ yolov7/requirements.txtï¼Œè®“å®ƒä¸è¦å¼·åˆ¶å®‰è£èˆŠç‰ˆã€‚

### æ¶æ§‹åœ–

<img width="938" height="625" alt="æˆªåœ– 2025-10-03 æ™šä¸Š7 33 03" src="https://github.com/user-attachments/assets/9c9644df-cdf7-4dac-8921-6c130bc3881e" />


### ç¶²é å±•ç¤º


<img width="1000" height="950" alt="å¯µç‰©æ™ºèƒ½ç›£æ§ç³»çµ±_ç‹—ç‹—è¶´ä¸‹" src="https://github.com/user-attachments/assets/d6933a09-7731-46a2-b449-885ec5f45608" />
<img width="1000" height="900" alt="å¯µç‰©æ™ºèƒ½ç›£æ§ç³»çµ±_ç‹—ç‹—ä¸Šå»æ‰€" src="https://github.com/user-attachments/assets/f81c39fa-014d-490b-9a66-4f393df366ab" />
<img width="1000" height="950" alt="å¯µç‰©æ™ºèƒ½ç›£æ§ç³»çµ±_ç‹—ç‹—åƒé£¯" src="https://github.com/user-attachments/assets/b6183956-fb33-4b7b-a44a-c3c64f87c7ea" />
<img width="1000" height="800" alt="å¯µç‰©æ™ºèƒ½ç›£æ§ç³»çµ±_åœ–è¡¨" src="https://github.com/user-attachments/assets/f49bc1c7-fee2-480f-9d35-80639bc8bc32" />
